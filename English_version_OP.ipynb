{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI60YtULUav0",
        "outputId": "e44af430-3ff6-4ffa-b3ef-ff30e1cc7aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ordered-prompt'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 133 (delta 39), reused 36 (delta 36), pack-reused 86 (from 1)\u001b[K\n",
            "Receiving objects: 100% (133/133), 28.54 MiB | 15.66 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "/content/ordered-prompt\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "# 1. å…‹éš†å®˜æ–¹ä»“åº“\n",
        "!git clone https://github.com/yaolu/ordered-prompt.git\n",
        "\n",
        "# 2. è¿›å…¥é¡¹ç›®ç›®å½•\n",
        "%cd ordered-prompt\n",
        "\n",
        "# 3. å®‰è£…ä¾èµ–åº“\n",
        "# è®ºæ–‡ä»£ç ä¸»è¦ä¾èµ– transformers å’Œ torch\n",
        "# ä¸ºäº†å…¼å®¹æ€§ï¼Œå»ºè®®å®‰è£…ä¸€èˆ¬ç‰ˆæœ¬ï¼Œå¦‚æœæœ‰æŠ¥é”™å†æŒ‡å®šç‰ˆæœ¬\n",
        "\n",
        "!pip install transformers scikit-learn numpy scipy torch pyyaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å‡è®¾ä»“åº“ä¸­æœ‰ data æ–‡ä»¶å¤¹å’Œä¸‹è½½è„šæœ¬\n",
        "# å¦‚æœæ²¡æœ‰è„šæœ¬ï¼Œé€šå¸¸é€šè¿‡ HuggingFace datasets åº“è‡ªåŠ¨ä¸‹è½½\n",
        "# è¿™é‡Œå°è¯•è¿è¡Œä»“åº“è‡ªå¸¦çš„æ•°æ®è„šæœ¬ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰\n",
        "!bash scripts/download_data.sh\n",
        "\n",
        "# æˆ–è€…ï¼Œæ‚¨å¯ä»¥æ‰‹åŠ¨ä¸Šä¼ æ•°æ®ï¼š\n",
        "# ç‚¹å‡»å·¦ä¾§æ–‡ä»¶å¤¹å›¾æ ‡ -> ç›´æ¥æ‹–æ‹½æ‚¨çš„ sst-2 æ•°æ®é›†æ–‡ä»¶åˆ° ordered-prompt/data/ ç›®å½•ä¸‹"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLMoaG0MVEhx",
        "outputId": "8245fb07-c0c4-4944-f9d4-bd95fe90505a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bash: scripts/download_data.sh: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æŸ¥çœ‹ä»“åº“é‡Œçš„æ–‡ä»¶åˆ—è¡¨ï¼Œæ‰¾åˆ°çœŸæ­£çš„ python ä¸»ç¨‹åºåå­—\n",
        "!ls -R /content/ordered-prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jelVU5hfV3xh",
        "outputId": "fd6e077e-d8ad-4033-8cc2-a6c7b78cea32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ordered-prompt:\n",
            "augment.py\tdataset.py   gpt3_augument.py\t  gpt3_utils.py  model.py\n",
            "compeletion.py\tdebugger.py  gpt3_compeletion.py  __init__.py\t README.md\n",
            "config\t\tentropy.py   gpt3_prediction.py   LICENSE\t script\n",
            "data\t\tevaluate.py  gpt3.py\t\t  main.py\t utils.py\n",
            "\n",
            "/content/ordered-prompt/config:\n",
            "agnews.yaml  cr.yaml\t   mpqa.yaml  rte.yaml\t sst5.yaml  trec.yaml\n",
            "cb.yaml      dbpedia.yaml  mr.yaml    sst2.yaml  subj.yaml\n",
            "\n",
            "/content/ordered-prompt/data:\n",
            "agnews\tcb  cr\tdbpedia  mpqa  mr  rte\tsst2  sst5  subj  trec\n",
            "\n",
            "/content/ordered-prompt/data/agnews:\n",
            "classes.txt  dev_subsample.jsonl  test.jsonl  train.jsonl\n",
            "\n",
            "/content/ordered-prompt/data/cb:\n",
            "dev.jsonl  dev_subsample.jsonl\ttest.jsonl  train.jsonl\n",
            "\n",
            "/content/ordered-prompt/data/cr:\n",
            "dev_subsample.jsonl  test.jsonl  train.jsonl\n",
            "\n",
            "/content/ordered-prompt/data/dbpedia:\n",
            "classes.txt  dev_subsample.jsonl  readme.txt  test.jsonl  train_subset.jsonl\n",
            "\n",
            "/content/ordered-prompt/data/mpqa:\n",
            "dev_subsample.jsonl  test.jsonl  train.jsonl\n",
            "\n",
            "/content/ordered-prompt/data/mr:\n",
            "dev_subsample.jsonl  test.jsonl  train.jsonl\n",
            "\n",
            "/content/ordered-prompt/data/rte:\n",
            "dev.jsonl  dev_subsample.jsonl\ttest.jsonl  train.jsonl\n",
            "\n",
            "/content/ordered-prompt/data/sst2:\n",
            "dev.jsonl  dev_subsample.jsonl\ttest.jsonl  train.jsonl\n",
            "\n",
            "/content/ordered-prompt/data/sst5:\n",
            "dev.jsonl  dev_subsample.jsonl\ttest.jsonl  train.jsonl\n",
            "\n",
            "/content/ordered-prompt/data/subj:\n",
            "dev_subsample.jsonl  test.jsonl  train.jsonl\n",
            "\n",
            "/content/ordered-prompt/data/trec:\n",
            "dev_subsample.jsonl  test.jsonl  train.jsonl\n",
            "\n",
            "/content/ordered-prompt/script:\n",
            "gpt3\t       run_cb.sh  run_dbpedia.sh  run_mr.sh   run_sst2.sh  run_subj.sh\n",
            "run_agnews.sh  run_cr.sh  run_mpqa.sh\t  run_rte.sh  run_sst5.sh  run_trec.sh\n",
            "\n",
            "/content/ordered-prompt/script/gpt3:\n",
            "run_gpt3_agnews_davinci.sh   run_gpt3_mpqa_davinci.sh  run_gpt3_sst5_davinci.sh\n",
            "run_gpt3_agnews.sh\t     run_gpt3_mpqa.sh\t       run_gpt3_sst5.sh\n",
            "run_gpt3_cb_davinci.sh\t     run_gpt3_mr_davinci.sh    run_gpt3_subj_davinci.sh\n",
            "run_gpt3_cb.sh\t\t     run_gpt3_mr.sh\t       run_gpt3_subj.sh\n",
            "run_gpt3_cr_davinci.sh\t     run_gpt3_rte_davinci.sh   run_gpt3_trec_davinci.sh\n",
            "run_gpt3_cr.sh\t\t     run_gpt3_rte.sh\t       run_gpt3_trec.sh\n",
            "run_gpt3_dbpedia_davinci.sh  run_gpt3_sst2_davinci.sh\n",
            "run_gpt3_dbpedia.sh\t     run_gpt3_sst2.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# è¿è¡Œä¸»ç¨‹åº\n",
        "# --model_name_or_path: ä½¿ç”¨ huggingface ä¸Šçš„ \"gpt2\" (0.1Bå‚æ•°)\n",
        "# --task_name: ä»»åŠ¡åç§°ï¼Œæ¯”å¦‚ sst2\n",
        "# --num_shots: 4 (è®ºæ–‡æ ¸å¿ƒè®¾ç½®)\n",
        "# --method: probe (ä½¿ç”¨è®ºæ–‡æå‡ºçš„æ¢æµ‹æ–¹æ³•)\n",
        "\n",
        "!python main.py \\\n",
        "    --model_name_or_path gpt2 \\\n",
        "    --task_name sst2 \\\n",
        "    --num_shots 4 \\\n",
        "    --method probe \\\n",
        "    --probe_metric global_entropy \\\n",
        "    --output_dir ./output_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4obtEdtVHRS",
        "outputId": "5cc0a617-49bc-4115-e68b-51bf69d14577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-09 13:42:32.172248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765287752.191663    2733 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765287752.197586    2733 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765287752.212509    2733 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765287752.212532    2733 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765287752.212536    2733 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765287752.212541    2733 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-09 13:42:32.217074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: main.py [-h] --config CONFIG [--model MODEL] [--seed SEED]\n",
            "               [--nshot NSHOT] [--test_data_path TEST_DATA_PATH]\n",
            "               [--output OUTPUT] [--generate] [--ngram NGRAM]\n",
            "               [--max_generation_length MAX_GENERATION_LENGTH]\n",
            "               [--temperature TEMPERATURE] [--do_sample] [--topk TOPK]\n",
            "               [--train_sample_mode TRAIN_SAMPLE_MODE]\n",
            "main.py: error: the following arguments are required: --config/-c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. å°è¯•å®šä½ main.py æ‰€åœ¨çš„çœŸæ­£è·¯å¾„\n",
        "target_dir = \"/content/ordered-prompt\"\n",
        "if not os.path.exists(os.path.join(target_dir, \"main.py\")):\n",
        "    # æˆ–è€…æ˜¯è¿™ä¸€å±‚\n",
        "    target_dir = \"/content/ordered-prompt/ordered-prompt\"\n",
        "\n",
        "# 2. è¿›å…¥è¯¥ç›®å½•\n",
        "os.chdir(target_dir)\n",
        "print(f\"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
        "\n",
        "# 3. å†æ¬¡ç¡®è®¤æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
        "!ls -F main.py config/ script/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSK9wD0aVQs8",
        "outputId": "b7f48d39-9b7c-4e27-da21-7e26df04b3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å½“å‰å·¥ä½œç›®å½•: /content/ordered-prompt\n",
            "main.py\n",
            "\n",
            "config/:\n",
            "agnews.yaml  cr.yaml\t   mpqa.yaml  rte.yaml\t sst5.yaml  trec.yaml\n",
            "cb.yaml      dbpedia.yaml  mr.yaml    sst2.yaml  subj.yaml\n",
            "\n",
            "script/:\n",
            "gpt3/\t       run_cb.sh  run_dbpedia.sh  run_mr.sh   run_sst2.sh  run_subj.sh\n",
            "run_agnews.sh  run_cr.sh  run_mpqa.sh\t  run_rte.sh  run_sst5.sh  run_trec.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat script/run_sst2.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5j9EpITWedX",
        "outputId": "2b1ad024-67ae-40f7-8621-74561c4fcbb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/bin/bash\n",
            "\n",
            "MAIN_DIR=$(pwd)\n",
            "DATASET=sst2\n",
            "LOGDIR=experiment_32shot/$DATASET;\n",
            "SAMPLE_MODE=balance\n",
            "\n",
            "mkdir -p $LOGDIR\n",
            "\n",
            "for NSHOT in 4;\n",
            "do\n",
            "\n",
            "for MODEL in gpt2 gpt2-medium gpt2-large gpt2-xl;\n",
            "do\n",
            "for SEED in 1 2 3 4 5;\n",
            "do\n",
            "\n",
            "  for N in 3 5;\n",
            "  do\n",
            "     python main.py --config config/$DATASET.yaml \\\n",
            "     --nshot $NSHOT --model $MODEL --output $LOGDIR --seed $SEED \\\n",
            "     --ngram $N --generate --temperature 2.0 --topk 20 --do_sample\n",
            "\n",
            "     echo \"python main.py --config config/$DATASET.yaml \\\n",
            "     --nshot $NSHOT --model $MODEL --output $LOGDIR --seed $SEED \\\n",
            "     --ngram $N --generate --temperature 2.0 --topk 20 --do_sample\"\n",
            "  done;\n",
            "\n",
            "  cd $LOGDIR;\n",
            "\n",
            "  for f in generate*;\n",
            "  do\n",
            "      python \"$MAIN_DIR\"/augment.py $f\n",
            "  done;\n",
            "\n",
            "  mkdir ckpt;\n",
            "  mv *.pkl ckpt;\n",
            "\n",
            "  OUTPUT=dev_${DATASET}_${NSHOT}_shot_${MODEL}_seed${SEED}.jsonl\n",
            "  cat augment_*.jsonl > $OUTPUT\n",
            "  mv augment_*.jsonl ckpt\n",
            "\n",
            "  cd \"${MAIN_DIR}\" || exit;\n",
            "\n",
            "  echo \"python main.py --config config/$DATASET.yaml \\\n",
            "     --nshot $NSHOT --model $MODEL --output $LOGDIR --seed $SEED --test_data_path $LOGDIR/$OUTPUT;\"\n",
            "\n",
            "  python main.py --config config/$DATASET.yaml \\\n",
            "     --nshot $NSHOT --model $MODEL --output $LOGDIR --seed $SEED --test_data_path $LOGDIR/$OUTPUT\n",
            "\n",
            "  mv $LOGDIR/${DATASET}_${NSHOT}_shot_${MODEL}_seed${SEED}_*.pkl $LOGDIR/fake_${DATASET}_${NSHOT}_shot_${MODEL}_seed${SEED}.pkl\n",
            "  python main.py --config config/$DATASET.yaml \\\n",
            "     --nshot $NSHOT --model $MODEL --output $LOGDIR --seed $SEED\n",
            "  mv $LOGDIR/${DATASET}_${NSHOT}_shot_${MODEL}_seed${SEED}_*.pkl $LOGDIR/true_${DATASET}_${NSHOT}_shot_${MODEL}_seed${SEED}.pkl\n",
            "\n",
            "  python entropy.py --true $LOGDIR/true_${DATASET}_${NSHOT}_shot_${MODEL}_seed${SEED}.pkl \\\n",
            "                    --fake $LOGDIR/fake_${DATASET}_${NSHOT}_shot_${MODEL}_seed${SEED}.pkl \\\n",
            "                    --topk 4 --save $LOGDIR/result_${DATASET}_${NSHOT}_shot_${MODEL}_seed${SEED}.json\n",
            "\n",
            "done;\n",
            "\n",
            "done;\n",
            "\n",
            "done;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "# --- é…ç½®å‚æ•° (æ¨¡æ‹Ÿè„šæœ¬ä¸­çš„å˜é‡) ---\n",
        "MAIN_DIR = os.getcwd() # å½“å‰ç›®å½•ï¼Œåº”è¯¥æ˜¯ /content/ordered-prompt\n",
        "DATASET = \"sst2\"\n",
        "NSHOT = 4\n",
        "MODEL = \"gpt2\"         # ä¸ºäº†é€Ÿåº¦å…ˆç”¨ gpt2ï¼Œè·‘é€šåå†æ¢ gpt2-xl\n",
        "SEED = 1               # åªè·‘ç§å­ 1\n",
        "LOGDIR = f\"experiment_32shot/{DATASET}\" # ä¿æŒå’Œè„šæœ¬ä¸€è‡´çš„ç›®å½•ç»“æ„\n",
        "\n",
        "# åˆ›å»ºå®éªŒç›®å½•\n",
        "os.makedirs(LOGDIR, exist_ok=True)\n",
        "\n",
        "print(f\"ğŸš€ å¼€å§‹å¤ç°æµç¨‹: Model={MODEL}, Task={DATASET}, Seed={SEED}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# ==========================================\n",
        "# æ­¥éª¤ 1: ç”Ÿæˆæ¢æµ‹é›† (Generate Probing Set)\n",
        "# ==========================================\n",
        "print(\"Step 1: ç”Ÿæˆæ¢æµ‹æ•°æ® (Generating)...\")\n",
        "# è„šæœ¬é‡Œå¾ªç¯äº† ngram 3 å’Œ 5ï¼Œæˆ‘ä»¬ç…§åš\n",
        "for ngram in [3, 5]:\n",
        "    cmd = (\n",
        "        f\"python main.py --config config/{DATASET}.yaml \"\n",
        "        f\"--nshot {NSHOT} --model {MODEL} --output {LOGDIR} --seed {SEED} \"\n",
        "        f\"--ngram {ngram} --generate --temperature 2.0 --topk 20 --do_sample\"\n",
        "    )\n",
        "    print(f\"æ‰§è¡Œ: {cmd}\")\n",
        "    os.system(cmd)\n",
        "\n",
        "# ==========================================\n",
        "# æ­¥éª¤ 2: æ•°æ®æ¸…æ´—ä¸åˆå¹¶ (Augment)\n",
        "# ==========================================\n",
        "print(\"\\nStep 2: æ¸…æ´—æ•°æ® (Augmenting)...\")\n",
        "# æ‰¾åˆ°ç”Ÿæˆçš„æ–‡ä»¶ (generate*)\n",
        "gen_files = glob.glob(os.path.join(LOGDIR, \"generate*\"))\n",
        "\n",
        "for f in gen_files:\n",
        "    # è°ƒç”¨ augment.py å¤„ç†æ¯ä¸ªç”Ÿæˆçš„æ–‡ä»¶\n",
        "    cmd = f\"python augment.py {f}\"\n",
        "    print(f\"æ‰§è¡Œ: {cmd}\")\n",
        "    os.system(cmd)\n",
        "\n",
        "# æ•´ç†æ–‡ä»¶ (æŠŠä¸­é—´æ–‡ä»¶ç§»åˆ° ckpt æ–‡ä»¶å¤¹ï¼Œé˜²æ­¢æ··ä¹±)\n",
        "ckpt_dir = os.path.join(LOGDIR, \"ckpt\")\n",
        "os.makedirs(ckpt_dir, exist_ok=True)\n",
        "\n",
        "# ç§»åŠ¨ .pkl æ–‡ä»¶\n",
        "for pkl in glob.glob(\"*.pkl\"):\n",
        "    shutil.move(pkl, ckpt_dir)\n",
        "\n",
        "# åˆå¹¶æ‰€æœ‰ augment_*.jsonl åˆ°ä¸€ä¸ªæ–‡ä»¶\n",
        "output_filename = f\"dev_{DATASET}_{NSHOT}_shot_{MODEL}_seed{SEED}.jsonl\"\n",
        "output_path = os.path.join(LOGDIR, output_filename)\n",
        "aug_files = glob.glob(\"augment_*.jsonl\")\n",
        "\n",
        "with open(output_path, 'w') as outfile:\n",
        "    for fname in aug_files:\n",
        "        with open(fname) as infile:\n",
        "            outfile.write(infile.read())\n",
        "        # ç§»åŠ¨å¤„ç†å®Œçš„ç¢ç‰‡æ–‡ä»¶åˆ° ckpt\n",
        "        shutil.move(fname, ckpt_dir)\n",
        "\n",
        "print(f\"ç”Ÿæˆçš„æ¢æµ‹é›†å·²åˆå¹¶è‡³: {output_path}\")\n",
        "\n",
        "# ==========================================\n",
        "# æ­¥éª¤ 3: åœ¨æ¢æµ‹é›†ä¸Šæ¨ç† (Inference on Fake Data)\n",
        "# ==========================================\n",
        "print(\"\\nStep 3: è®¡ç®—æ¢æµ‹é›†è¡¨ç° (Inference on Probing Set)...\")\n",
        "# æ³¨æ„ï¼šè¿™é‡ŒæŒ‡å®šäº† --test_data_path ä¸ºæˆ‘ä»¬åˆšåˆšç”Ÿæˆçš„å‡æ•°æ®\n",
        "cmd = (\n",
        "    f\"python main.py --config config/{DATASET}.yaml \"\n",
        "    f\"--nshot {NSHOT} --model {MODEL} --output {LOGDIR} --seed {SEED} \"\n",
        "    f\"--test_data_path {output_path}\"\n",
        ")\n",
        "print(f\"æ‰§è¡Œ: {cmd}\")\n",
        "os.system(cmd)\n",
        "\n",
        "# é‡å‘½åç»“æœæ–‡ä»¶ä¸º fake_...pkl\n",
        "# è„šæœ¬é€»è¾‘ï¼šmain.py ä¼šç”Ÿæˆä¸€ä¸ªç±»ä¼¼ {DATASET}_{NSHOT}_shot_{MODEL}_seed{SEED}_xxxx.pkl çš„æ–‡ä»¶\n",
        "# æˆ‘ä»¬éœ€è¦æ‰¾åˆ°æœ€æ–°çš„é‚£ä¸ª pkl å¹¶é‡å‘½å\n",
        "res_files = glob.glob(os.path.join(LOGDIR, f\"{DATASET}_{NSHOT}_shot_{MODEL}_seed{SEED}_*.pkl\"))\n",
        "# å‡è®¾åªæœ‰ä¸€ä¸ªæˆ–æœ€æ–°çš„ä¸€ä¸ªæ˜¯ç›®æ ‡æ–‡ä»¶\n",
        "if res_files:\n",
        "    latest_file = max(res_files, key=os.path.getctime)\n",
        "    fake_pkl = os.path.join(LOGDIR, f\"fake_{DATASET}_{NSHOT}_shot_{MODEL}_seed{SEED}.pkl\")\n",
        "    os.rename(latest_file, fake_pkl)\n",
        "    print(f\"Fake ç»“æœå·²ä¿å­˜: {fake_pkl}\")\n",
        "else:\n",
        "    print(\"âŒ é”™è¯¯: æœªæ‰¾åˆ° Fake æ¨ç†ç»“æœ pkl æ–‡ä»¶\")\n",
        "\n",
        "# ==========================================\n",
        "# æ­¥éª¤ 4: åœ¨çœŸå®éªŒè¯é›†ä¸Šæ¨ç† (Inference on True Data)\n",
        "# ==========================================\n",
        "print(\"\\nStep 4: è®¡ç®—çœŸå®æ•°æ®è¡¨ç° (Inference on True Data)...\")\n",
        "# è¿™æ¬¡ä¸å¸¦ --test_data_pathï¼Œé»˜è®¤ç”¨çœŸå®éªŒè¯é›†\n",
        "cmd = (\n",
        "    f\"python main.py --config config/{DATASET}.yaml \"\n",
        "    f\"--nshot {NSHOT} --model {MODEL} --output {LOGDIR} --seed {SEED}\"\n",
        ")\n",
        "print(f\"æ‰§è¡Œ: {cmd}\")\n",
        "os.system(cmd)\n",
        "\n",
        "# é‡å‘½åç»“æœæ–‡ä»¶ä¸º true_...pkl\n",
        "res_files = glob.glob(os.path.join(LOGDIR, f\"{DATASET}_{NSHOT}_shot_{MODEL}_seed{SEED}_*.pkl\"))\n",
        "if res_files:\n",
        "    latest_file = max(res_files, key=os.path.getctime)\n",
        "    true_pkl = os.path.join(LOGDIR, f\"true_{DATASET}_{NSHOT}_shot_{MODEL}_seed{SEED}.pkl\")\n",
        "    os.rename(latest_file, true_pkl)\n",
        "    print(f\"True ç»“æœå·²ä¿å­˜: {true_pkl}\")\n",
        "else:\n",
        "    print(\"âŒ é”™è¯¯: æœªæ‰¾åˆ° True æ¨ç†ç»“æœ pkl æ–‡ä»¶\")\n",
        "\n",
        "# ==========================================\n",
        "# æ­¥éª¤ 5: è®¡ç®—ç†µå¹¶è¾“å‡ºç»“æœ (Entropy Selection)\n",
        "# ==========================================\n",
        "print(\"\\nStep 5: è®¡ç®—ç†µå¹¶ç­›é€‰æœ€ä½³ Prompt (Entropy Calculation)...\")\n",
        "result_json = os.path.join(LOGDIR, f\"result_{DATASET}_{NSHOT}_shot_{MODEL}_seed{SEED}.json\")\n",
        "\n",
        "cmd = (\n",
        "    f\"python entropy.py --true {true_pkl} \"\n",
        "    f\"--fake {fake_pkl} \"\n",
        "    f\"--topk 4 --save {result_json}\"\n",
        ")\n",
        "print(f\"æ‰§è¡Œ: {cmd}\")\n",
        "os.system(cmd)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"âœ… å¤ç°å®Œæˆï¼è¯·æ£€æŸ¥ç»“æœæ–‡ä»¶: {result_json}\")\n",
        "print(\"ä½ å¯ä»¥æ‰“å¼€è¯¥ JSON æ–‡ä»¶æŸ¥çœ‹ç­›é€‰å‡ºçš„æœ€ä½³ Prompt é¡ºåºåŠå…¶æ•ˆæœã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "fcivMJ8DWsj6",
        "outputId": "b8ec51fc-7343-4e3c-8ef5-670b7e37e973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ å¼€å§‹å¤ç°æµç¨‹: Model=gpt2, Task=sst2, Seed=1\n",
            "--------------------------------------------------\n",
            "Step 1: ç”Ÿæˆæ¢æµ‹æ•°æ® (Generating)...\n",
            "æ‰§è¡Œ: python main.py --config config/sst2.yaml --nshot 4 --model gpt2 --output experiment_32shot/sst2 --seed 1 --ngram 3 --generate --temperature 2.0 --topk 20 --do_sample\n",
            "æ‰§è¡Œ: python main.py --config config/sst2.yaml --nshot 4 --model gpt2 --output experiment_32shot/sst2 --seed 1 --ngram 5 --generate --temperature 2.0 --topk 20 --do_sample\n",
            "\n",
            "Step 2: æ¸…æ´—æ•°æ® (Augmenting)...\n",
            "ç”Ÿæˆçš„æ¢æµ‹é›†å·²åˆå¹¶è‡³: experiment_32shot/sst2/dev_sst2_4_shot_gpt2_seed1.jsonl\n",
            "\n",
            "Step 3: è®¡ç®—æ¢æµ‹é›†è¡¨ç° (Inference on Probing Set)...\n",
            "æ‰§è¡Œ: python main.py --config config/sst2.yaml --nshot 4 --model gpt2 --output experiment_32shot/sst2 --seed 1 --test_data_path experiment_32shot/sst2/dev_sst2_4_shot_gpt2_seed1.jsonl\n",
            "âŒ é”™è¯¯: æœªæ‰¾åˆ° Fake æ¨ç†ç»“æœ pkl æ–‡ä»¶\n",
            "\n",
            "Step 4: è®¡ç®—çœŸå®æ•°æ®è¡¨ç° (Inference on True Data)...\n",
            "æ‰§è¡Œ: python main.py --config config/sst2.yaml --nshot 4 --model gpt2 --output experiment_32shot/sst2 --seed 1\n",
            "âŒ é”™è¯¯: æœªæ‰¾åˆ° True æ¨ç†ç»“æœ pkl æ–‡ä»¶\n",
            "\n",
            "Step 5: è®¡ç®—ç†µå¹¶ç­›é€‰æœ€ä½³ Prompt (Entropy Calculation)...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'true_pkl' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1427945189.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m cmd = (\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;34mf\"python entropy.py --true {true_pkl} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;34mf\"--fake {fake_pkl} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;34mf\"--topk 4 --save {result_json}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'true_pkl' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. å¼ºåˆ¶è¿›å…¥ä»£ç ä»“åº“ç›®å½•\n",
        "%cd /content/ordered-prompt\n",
        "\n",
        "# 2. å†æ¬¡ç¡®è®¤æ–‡ä»¶ç¡®å®åœ¨è¿™é‡Œ (åº”è¯¥èƒ½çœ‹åˆ° main.py)\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78XXIPXrYR9O",
        "outputId": "2d3e68c4-b9d0-45e5-cf28-002c647c5941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ordered-prompt\n",
            "augment.py\tentropy.py\t     gpt3.py\t    ordered-prompt\n",
            "compeletion.py\tevaluate.py\t     gpt3_utils.py  __pycache__\n",
            "config\t\texperiment_32shot    __init__.py    README.md\n",
            "data\t\tgpt3_augument.py     LICENSE\t    script\n",
            "dataset.py\tgpt3_compeletion.py  main.py\t    utils.py\n",
            "debugger.py\tgpt3_prediction.py   model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# è¿è¡Œ Step 4: åœ¨çœŸå®æ•°æ®ä¸Šè¯„ä¼° (ä¸å¸¦ --test_data_path å‚æ•°)\n",
        "# è¿™ä¸€æ­¥ä¼šç›´æ¥è¯»å– data/sst2/ ä¸‹çš„æ–‡ä»¶ï¼ŒéªŒè¯æ¨¡å‹æ˜¯å¦å·¥ä½œæ­£å¸¸\n",
        "\n",
        "!python main.py \\\n",
        "    --config config/sst2.yaml \\\n",
        "    --nshot 4 \\\n",
        "    --model gpt2 \\\n",
        "    --output experiment_32shot/sst2 \\\n",
        "    --seed 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELUlODecX6HX",
        "outputId": "2cb951fa-6b7f-48e6-fb68-2db74a3ef483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-09 13:52:43.071531: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765288363.090557    5456 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765288363.096473    5456 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765288363.112120    5456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765288363.112143    5456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765288363.112148    5456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765288363.112151    5456 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-09 13:52:43.116623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Namespace(config='config/sst2.yaml', model='gpt2', seed=1, nshot=4, test_data_path='', output='experiment_32shot/sst2', generate=False, ngram=0, max_generation_length=128, temperature=1.0, do_sample=False, topk=-1, train_sample_mode='')\n",
            "override n-shot from 1 to 4\n",
            "{'train_data_path': 'data/sst2/train.jsonl', 'test_data_path': 'data/sst2/dev_subsample.jsonl', 'tokenizer_path': 'distilgpt2', 'n_shot': 4, 'label_mapping': {'0': 'negative', '1': 'positive'}, 'corpus_params': {'sentence_1_str': 'sentence', 'label_str': 'label'}, 'template': \"f'Review: {sentence_1}\\\\nSentiment: {label_text}\\\\n\\\\n'\", 'sample_mode': 'balance', 'sentence_pair': False, 'permutation_max_size': 24}\n",
            "config.json: 100% 665/665 [00:00<00:00, 5.26MB/s]\n",
            "model.safetensors: 100% 548M/548M [00:04<00:00, 113MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 940kB/s]\n",
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 269kB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 5.36MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 7.25MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 10.5MB/s]\n",
            "  0% 0/256 [00:00<?, ?it/s]Use subset of full permutations\n",
            "train_prompts_length:  172\n",
            "100% 256/256 [01:40<00:00,  2.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# å®šä¹‰å‚æ•°\n",
        "LOGDIR = \"experiment_32shot/sst2\"\n",
        "# ç¡®ä¿ç›®å½•å­˜åœ¨\n",
        "os.makedirs(LOGDIR, exist_ok=True)\n",
        "\n",
        "print(\"ğŸš€ æ­£åœ¨é‡æ–°å°è¯•ç”Ÿæˆæ¢æµ‹é›† (Probing Set)...\")\n",
        "\n",
        "# è¿è¡Œç”Ÿæˆå‘½ä»¤ (åªè·‘ ngram=3 ä»¥èŠ‚çœæ—¶é—´)\n",
        "# æ³¨æ„ï¼šæˆ‘åŠ äº†æ‰“å°ï¼Œæ–¹ä¾¿çœ‹å®ƒåˆ°åº•ç”Ÿæˆäº†ä»€ä¹ˆæ–‡ä»¶\n",
        "cmd = (\n",
        "    \"python main.py \"\n",
        "    \"--config config/sst2.yaml \"\n",
        "    \"--nshot 4 \"\n",
        "    \"--model gpt2 \"\n",
        "    \"--output experiment_32shot/sst2 \"\n",
        "    \"--seed 1 \"\n",
        "    \"--ngram 3 \"\n",
        "    \"--generate \"         # å…³é”®å‚æ•°ï¼šå¼€å¯ç”Ÿæˆæ¨¡å¼\n",
        "    \"--temperature 2.0 \"  # å…³é”®å‚æ•°ï¼šé«˜æ¸©åº¦å¢åŠ å¤šæ ·æ€§\n",
        "    \"--topk 20 \"\n",
        "    \"--do_sample\"\n",
        ")\n",
        "\n",
        "print(f\"æ‰§è¡Œå‘½ä»¤: {cmd}\")\n",
        "exit_code = os.system(cmd)\n",
        "\n",
        "if exit_code == 0:\n",
        "    print(\"\\nâœ… ç”Ÿæˆå‘½ä»¤æ‰§è¡ŒæˆåŠŸï¼æ­£åœ¨æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶...\")\n",
        "    # æ£€æŸ¥ç›®å½•ä¸‹æœ‰æ²¡æœ‰ generate å¼€å¤´çš„æ–‡ä»¶\n",
        "    files = os.listdir(LOGDIR)\n",
        "    gen_files = [f for f in files if f.startswith(\"generate\")]\n",
        "\n",
        "    if gen_files:\n",
        "        print(f\"ğŸ‰ æˆåŠŸæ‰¾åˆ°ç”Ÿæˆæ–‡ä»¶: {gen_files}\")\n",
        "        print(\"ä¸‹ä¸€æ­¥ï¼šè¯·æŠŠè¿™äº›ä¹±ä¸ƒå…«ç³Ÿçš„ç”Ÿæˆæ–‡ä»¶æ¸…æ´—æˆæ ‡å‡†æ ¼å¼ã€‚\")\n",
        "\n",
        "        # ç«‹å³è¿è¡Œæ¸…æ´—è„šæœ¬\n",
        "        print(\"\\nğŸ§¹ æ­£åœ¨æ¸…æ´—æ•°æ® (Augment)...\")\n",
        "        for f in gen_files:\n",
        "            full_path = os.path.join(LOGDIR, f)\n",
        "            os.system(f\"python augment.py {full_path}\")\n",
        "\n",
        "        print(\"âœ… æ¸…æ´—å®Œæˆï¼ä½ åº”è¯¥èƒ½çœ‹åˆ° augment_ å¼€å¤´çš„ jsonl æ–‡ä»¶äº†ã€‚\")\n",
        "    else:\n",
        "        print(\"âš ï¸ å‘½ä»¤è·‘é€šäº†ï¼Œä½†æ²¡æ‰¾åˆ° 'generate' å¼€å¤´çš„æ–‡ä»¶ã€‚è¯·æ£€æŸ¥ä¸Šæ–¹æ—¥å¿—ã€‚\")\n",
        "else:\n",
        "    print(\"âŒ ç”Ÿæˆå‘½ä»¤å¤±è´¥ï¼è¯·æŸ¥çœ‹ä¸Šæ–¹çš„æŠ¥é”™æ—¥å¿—ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IoC8QrvYq2_",
        "outputId": "d23b65b1-d15a-45af-86c0-4a1b1ab408b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ æ­£åœ¨é‡æ–°å°è¯•ç”Ÿæˆæ¢æµ‹é›† (Probing Set)...\n",
            "æ‰§è¡Œå‘½ä»¤: python main.py --config config/sst2.yaml --nshot 4 --model gpt2 --output experiment_32shot/sst2 --seed 1 --ngram 3 --generate --temperature 2.0 --topk 20 --do_sample\n",
            "\n",
            "âœ… ç”Ÿæˆå‘½ä»¤æ‰§è¡ŒæˆåŠŸï¼æ­£åœ¨æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶...\n",
            "ğŸ‰ æˆåŠŸæ‰¾åˆ°ç”Ÿæˆæ–‡ä»¶: ['generate_3gram_sst2_4_shot_gpt2_seed1_balance_temperature2.0_top20_hashd12673.pkl']\n",
            "ä¸‹ä¸€æ­¥ï¼šè¯·æŠŠè¿™äº›ä¹±ä¸ƒå…«ç³Ÿçš„ç”Ÿæˆæ–‡ä»¶æ¸…æ´—æˆæ ‡å‡†æ ¼å¼ã€‚\n",
            "\n",
            "ğŸ§¹ æ­£åœ¨æ¸…æ´—æ•°æ® (Augment)...\n",
            "âœ… æ¸…æ´—å®Œæˆï¼ä½ åº”è¯¥èƒ½çœ‹åˆ° augment_ å¼€å¤´çš„ jsonl æ–‡ä»¶äº†ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "# ============================\n",
        "# 1. å¼ºåˆ¶ä¿®æ­£å·¥ä½œç›®å½•\n",
        "# ============================\n",
        "# æ£€æŸ¥å½“å‰æ˜¯å¦åœ¨ ordered-prompt ç›®å½•ï¼Œå¦‚æœä¸æ˜¯å°±è¿›å»\n",
        "current_dir = os.getcwd()\n",
        "if not current_dir.endswith(\"ordered-prompt\"):\n",
        "    print(f\"âš ï¸ å½“å‰ç›®å½•æ˜¯ {current_dir}ï¼Œæ­£åœ¨åˆ‡æ¢åˆ° /content/ordered-prompt ...\")\n",
        "    try:\n",
        "        os.chdir(\"/content/ordered-prompt\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"âŒ æ‰¾ä¸åˆ° /content/ordered-prompt ç›®å½•ï¼è¯·ç¡®è®¤ä½ æ˜¯å¦å…‹éš†äº†ä»£ç ã€‚\")\n",
        "        sys.exit(1)\n",
        "else:\n",
        "    print(f\"âœ… å½“å‰ç›®å½•æ­£ç¡®: {current_dir}\")\n",
        "\n",
        "# ============================\n",
        "# 2. æš´åŠ›å¯»æ‰¾å¹¶ä¿®å¤æ•°æ®æ–‡ä»¶\n",
        "# ============================\n",
        "LOGDIR = \"experiment_32shot/sst2\"\n",
        "TARGET_FILENAME = \"dev_sst2_4_shot_gpt2_seed1.jsonl\"\n",
        "TARGET_PATH = os.path.join(LOGDIR, TARGET_FILENAME)\n",
        "\n",
        "print(\"\\nğŸ•µï¸â€â™‚ï¸ æ­£åœ¨å…¨ç›˜æœç´¢ augment æ–‡ä»¶...\")\n",
        "\n",
        "# ç­–ç•¥ï¼šå“ªé‡Œæœ‰augmentæ–‡ä»¶ï¼Œå°±æŠ“è¿‡æ¥æ”¹å\n",
        "# 1. å…ˆæ‰¾å­æ–‡ä»¶å¤¹\n",
        "candidates_subdir = glob.glob(os.path.join(LOGDIR, \"augment_*.jsonl\"))\n",
        "# 2. å†æ‰¾æ ¹ç›®å½•\n",
        "candidates_root = glob.glob(\"augment_*.jsonl\")\n",
        "# 3. çœ‹çœ‹ç›®æ ‡æ–‡ä»¶æ˜¯ä¸æ˜¯å·²ç»å­˜åœ¨äº†\n",
        "target_exists = os.path.exists(TARGET_PATH)\n",
        "\n",
        "if target_exists:\n",
        "    print(f\"âœ… ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨: {TARGET_PATH} (ç›´æ¥ä½¿ç”¨)\")\n",
        "\n",
        "elif candidates_subdir:\n",
        "    src = candidates_subdir[0]\n",
        "    print(f\"ğŸ‘‰ åœ¨å­ç›®å½•æ‰¾åˆ°äº†: {src}\")\n",
        "    shutil.move(src, TARGET_PATH)\n",
        "    print(f\"âœ… å·²é‡å‘½åä¸º: {TARGET_PATH}\")\n",
        "\n",
        "elif candidates_root:\n",
        "    src = candidates_root[0]\n",
        "    print(f\"ğŸ‘‰ åœ¨æ ¹ç›®å½•æ‰¾åˆ°äº†: {src}\")\n",
        "    shutil.move(src, TARGET_PATH)\n",
        "    print(f\"âœ… å·²ç§»åŠ¨å¹¶é‡å‘½åä¸º: {TARGET_PATH}\")\n",
        "\n",
        "else:\n",
        "    print(\"âŒ ä¸¥é‡é”™è¯¯ï¼šåˆ°å¤„éƒ½æ‰¾ä¸åˆ° augment_*.jsonl æ–‡ä»¶ï¼\")\n",
        "    print(\"è¯·æ£€æŸ¥å·¦ä¾§æ–‡ä»¶æ ï¼Œexperiment_32shot/sst2/ ç›®å½•ä¸‹åˆ°åº•æœ‰æ²¡æœ‰ç”Ÿæˆè¿‡ jsonl æ–‡ä»¶ï¼Ÿ\")\n",
        "    # å¦‚æœçœŸçš„æ²¡äº†ï¼Œå¯èƒ½éœ€è¦é‡è·‘ç”Ÿæˆæ­¥éª¤ï¼Œè¿™é‡Œå…ˆä¸­æ­¢\n",
        "    sys.exit(1)\n",
        "\n",
        "# ============================\n",
        "# 3. ç»§ç»­è¿è¡Œ Step 3, 4, 5\n",
        "# ============================\n",
        "print(\"\\nğŸš€ æ–‡ä»¶ä¿®å¤å®Œæˆï¼Œå¼€å§‹è·‘æœ€åæµç¨‹ï¼\")\n",
        "\n",
        "# Step 3: å‡æ•°æ®è¯„åˆ†\n",
        "print(\"--- Step 3: Fake Data Eval ---\")\n",
        "exit_code = os.system(f\"python main.py --config config/sst2.yaml --nshot 4 --model gpt2 --output {LOGDIR} --seed 1 --test_data_path {TARGET_PATH}\")\n",
        "if exit_code != 0: raise RuntimeError(\"Step 3 è¿è¡Œå¤±è´¥\")\n",
        "\n",
        "# æ•´ç† Step 3 çš„ç»“æœ (fake pkl)\n",
        "fake_candidates = glob.glob(os.path.join(LOGDIR, \"sst2_4_shot_gpt2_seed1_*.pkl\"))\n",
        "if not fake_candidates: raise RuntimeError(\"Step 3 æ²¡ç”Ÿæˆ pkl ç»“æœ\")\n",
        "latest_fake = max(fake_candidates, key=os.path.getctime)\n",
        "FAKE_PKL = os.path.join(LOGDIR, \"fake_scores.pkl\")\n",
        "os.rename(latest_fake, FAKE_PKL)\n",
        "\n",
        "# Step 4: çœŸæ•°æ®è¯„åˆ† (æ£€æŸ¥æ˜¯å¦éœ€è¦è¡¥è·‘)\n",
        "print(\"--- Step 4: True Data Eval ---\")\n",
        "TRUE_PKL = os.path.join(LOGDIR, \"true_scores.pkl\")\n",
        "# æ£€æŸ¥ä¹‹å‰æ˜¯å¦å·²ç»ç”Ÿæˆè¿‡ true_scores\n",
        "if not os.path.exists(TRUE_PKL):\n",
        "    # æ‰¾ä¸€ä¸‹æœ‰æ²¡æœ‰æ²¡æ”¹åçš„\n",
        "    true_candidates = [f for f in glob.glob(os.path.join(LOGDIR, \"sst2_4_shot_gpt2_seed1_*.pkl\")) if \"fake\" not in f]\n",
        "    if true_candidates:\n",
        "        shutil.move(true_candidates[0], TRUE_PKL)\n",
        "        print(\"âœ… æ‰¾åˆ°æ—§çš„çœŸå®è¯„åˆ†æ–‡ä»¶ï¼Œå·²é‡å‘½åã€‚\")\n",
        "    else:\n",
        "        print(\"ğŸ”„ æ²¡æ‰¾åˆ°çœŸå®è¯„åˆ†æ–‡ä»¶ï¼Œæ­£åœ¨è¡¥è·‘ Step 4...\")\n",
        "        os.system(f\"python main.py --config config/sst2.yaml --nshot 4 --model gpt2 --output {LOGDIR} --seed 1\")\n",
        "        # æŠ“å–æ–°ç”Ÿæˆçš„æ–‡ä»¶\n",
        "        true_candidates = [f for f in glob.glob(os.path.join(LOGDIR, \"sst2_4_shot_gpt2_seed1_*.pkl\")) if \"fake\" not in f]\n",
        "        if true_candidates:\n",
        "            shutil.move(true_candidates[0], TRUE_PKL)\n",
        "        else:\n",
        "            raise RuntimeError(\"Step 4 è¿è¡Œå¤±è´¥ï¼Œæ²¡ç”Ÿæˆ pkl\")\n",
        "\n",
        "# Step 5: è®¡ç®—ç†µ\n",
        "print(\"--- Step 5: Final Entropy Calculation ---\")\n",
        "FINAL_JSON = os.path.join(LOGDIR, \"final_result.json\")\n",
        "os.system(f\"python entropy.py --true {TRUE_PKL} --fake {FAKE_PKL} --topk 4 --save {FINAL_JSON}\")\n",
        "\n",
        "if os.path.exists(FINAL_JSON):\n",
        "    import json\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ğŸ† å¤ç°æˆåŠŸï¼Best Prompt å¦‚ä¸‹ï¼š\")\n",
        "    with open(FINAL_JSON, 'r') as f:\n",
        "        print(json.dumps(json.load(f), indent=2))\n",
        "else:\n",
        "    print(\"âŒ æµç¨‹ç»“æŸï¼Œä½†æ²¡ç”Ÿæˆ JSONï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹æŠ¥é”™ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j6skPuDZfAI",
        "outputId": "a74edf61-5be8-4755-ef26-8767f91919b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… å½“å‰ç›®å½•æ­£ç¡®: /content/ordered-prompt\n",
            "\n",
            "ğŸ•µï¸â€â™‚ï¸ æ­£åœ¨å…¨ç›˜æœç´¢ augment æ–‡ä»¶...\n",
            "ğŸ‘‰ åœ¨å­ç›®å½•æ‰¾åˆ°äº†: experiment_32shot/sst2/augment_generate_3gram_sst2_4_shot_gpt2_seed1_balance_temperature2.0_top20_hashd12673.jsonl\n",
            "âœ… å·²é‡å‘½åä¸º: experiment_32shot/sst2/dev_sst2_4_shot_gpt2_seed1.jsonl\n",
            "\n",
            "ğŸš€ æ–‡ä»¶ä¿®å¤å®Œæˆï¼Œå¼€å§‹è·‘æœ€åæµç¨‹ï¼\n",
            "--- Step 3: Fake Data Eval ---\n",
            "--- Step 4: True Data Eval ---\n",
            "ğŸ”„ æ²¡æ‰¾åˆ°çœŸå®è¯„åˆ†æ–‡ä»¶ï¼Œæ­£åœ¨è¡¥è·‘ Step 4...\n",
            "--- Step 5: Final Entropy Calculation ---\n",
            "\n",
            "==================================================\n",
            "ğŸ† å¤ç°æˆåŠŸï¼Best Prompt å¦‚ä¸‹ï¼š\n",
            "{\n",
            "  \"acc_stats\": [\n",
            "    0.5672041666666666,\n",
            "    0.06688639298072684\n",
            "  ],\n",
            "  \"topk_acc_stats\": [\n",
            "    0.6543,\n",
            "    0.07380945061440303\n",
            "  ],\n",
            "  \"topk\": 4,\n",
            "  \"entropys\": [\n",
            "    1.5783735610181542e-06,\n",
            "    1.5783735610181542e-06,\n",
            "    1.5783735610181542e-06,\n",
            "    1.5783735610181542e-06,\n",
            "    1.5783735610181542e-06,\n",
            "    1.5783735610181542e-06,\n",
            "    1.5783735610181542e-06,\n",
            "    0.43291507546338787,\n",
            "    0.689734492670935,\n",
            "    1.5783735610181542e-06,\n",
            "    1.5783735610181542e-06,\n",
            "    0.28499889328570227,\n",
            "    1.5783735610181542e-06,\n",
            "    0.2623322442988144,\n",
            "    0.6465905855361525,\n",
            "    1.5783735610181542e-06,\n",
            "    0.12602328734947899,\n",
            "    1.5783735610181542e-06,\n",
            "    0.052171987463861744,\n",
            "    0.6406696864769208,\n",
            "    0.3834111178560703,\n",
            "    1.5783735610181542e-06,\n",
            "    0.12602328734947899,\n",
            "    0.6744715846546492\n",
            "  ],\n",
            "  \"acc\": [\n",
            "    0.5195,\n",
            "    0.5742,\n",
            "    0.5547,\n",
            "    0.5195,\n",
            "    0.5273,\n",
            "    0.5195,\n",
            "    0.5156,\n",
            "    0.6914,\n",
            "    0.5312,\n",
            "    0.5156,\n",
            "    0.5156,\n",
            "    0.6523,\n",
            "    0.5156,\n",
            "    0.5391,\n",
            "    0.7188,\n",
            "    0.5195,\n",
            "    0.5781,\n",
            "    0.5156,\n",
            "    0.5234,\n",
            "    0.6641,\n",
            "    0.5508,\n",
            "    0.5234,\n",
            "    0.625,\n",
            "    0.7031\n",
            "  ],\n",
            "  \"ckpt\": \"experiment_32shot/sst2/true_scores.pkl\",\n",
            "  \"ckpt_gen\": \"experiment_32shot/sst2/fake_scores.pkl\",\n",
            "  \"pearsonr_corr\": [\n",
            "    0.7414929100649356,\n",
            "    3.382340394634091e-05\n",
            "  ],\n",
            "  \"spearmanr_corr\": [\n",
            "    0.7702749913310377,\n",
            "    1.069564001707373e-05\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s266H7nIaqh-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}